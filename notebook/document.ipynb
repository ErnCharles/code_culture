{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d1f18ffc",
   "metadata": {},
   "source": [
    "### Data Ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "419cb18f",
   "metadata": {},
   "outputs": [],
   "source": [
    "### what exactly is a document data structure\n",
    "#page content\n",
    "#meta data\n",
    "from langchain_core.documents import Document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ed9a10d",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = Document(page_content=\"this is the main text content I am using to create rag\",\n",
    "               metadata={\n",
    "                   \"source\":\"example.txt\",\n",
    "                   \"page\":1,\n",
    "                   \"author\":\"Charles\",\n",
    "                   \"data_created\": \"2025-01-01\"\n",
    "               })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4431f9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(metadata={'source': 'example.txt', 'page': 1, 'author': 'Charles', 'data_created': '2025-01-01'}, page_content='this is the main text content I am using to create rag')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84a8fc82",
   "metadata": {},
   "outputs": [],
   "source": [
    "##create a simple text file\n",
    "import os\n",
    "os.makedirs(\"../data/text_files\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ff0b1f0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample text files created!\n"
     ]
    }
   ],
   "source": [
    "sample_texts={\n",
    "    \"../data/text_files/python_intro.txt\":\"\"\"Python Programming Introduction\n",
    "\n",
    "Python is a high-level, interpreted programming language known for its simplicity and readability.\n",
    "Created by Guido van Rossum and first released in 1991, Python has become one of the most popular\n",
    "programming languages in the world.\n",
    "\n",
    "Key Features:\n",
    "- Easy to learn and use\n",
    "- Extensive standard library\n",
    "- Cross-platform compatibility\n",
    "- Strong community support\n",
    "\n",
    "Python is widely used in web development, data science, artificial intelligence, and automation.\"\"\",\n",
    "    \n",
    "    \"../data/text_files/machine_learning.txt\": \"\"\"Machine Learning Basics\n",
    "\n",
    "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
    "from experience without being explicitly programmed. It focuses on developing computer programs\n",
    "that can access data and use it to learn for themselves.\n",
    "\n",
    "Types of Machine Learning:\n",
    "1. Supervised Learning: Learning with labeled data\n",
    "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
    "3. Reinforcement Learning: Learning through rewards and penalties\n",
    "\n",
    "Applications include image recognition, speech processing, and recommendation systems\n",
    "    \n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "}\n",
    "\n",
    "for filepath,content in sample_texts.items():\n",
    "    with open(filepath,'w',encoding=\"utf-8\") as f:\n",
    "        f.write(content)\n",
    "\n",
    "print(\"Sample text files created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7044a2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\terng\\OneDrive\\Desktop\\py projects\\code_culture\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Document(metadata={'source': '../data/text_files/python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]\n"
     ]
    }
   ],
   "source": [
    "### reading text using langchain\n",
    "\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "\n",
    "\n",
    "loader = TextLoader(\"../data/text_files/python_intro.txt\",encoding=\"utf-8\")\n",
    "document = loader.load()\n",
    "print(document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ce6d262e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1026.63it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#### Directory loader loading all files from a directory instead of a single file\n",
    "from tqdm.auto import tqdm\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", # Pattern to match files basically the files we want to extract\n",
    "    loader_cls=TextLoader, #loader class to use since we are loading txt here we use textloader if it was pdf we would use a pdf loader\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "dir_loader.load()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e290b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 1222.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': '..\\\\data\\\\text_files\\\\machine_learning.txt'}, page_content='Machine Learning Basics\\n\\nMachine learning is a subset of artificial intelligence that enables systems to learn and improve\\nfrom experience without being explicitly programmed. It focuses on developing computer programs\\nthat can access data and use it to learn for themselves.\\n\\nTypes of Machine Learning:\\n1. Supervised Learning: Learning with labeled data\\n2. Unsupervised Learning: Finding patterns in unlabeled data\\n3. Reinforcement Learning: Learning through rewards and penalties\\n\\nApplications include image recognition, speech processing, and recommendation systems\\n\\n\\n    '),\n",
       " Document(metadata={'source': '..\\\\data\\\\text_files\\\\python_intro.txt'}, page_content='Python Programming Introduction\\n\\nPython is a high-level, interpreted programming language known for its simplicity and readability.\\nCreated by Guido van Rossum and first released in 1991, Python has become one of the most popular\\nprogramming languages in the world.\\n\\nKey Features:\\n- Easy to learn and use\\n- Extensive standard library\\n- Cross-platform compatibility\\n- Strong community support\\n\\nPython is widely used in web development, data science, artificial intelligence, and automation.')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tqdm.auto import tqdm\n",
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "dir_loader = DirectoryLoader(\n",
    "    \"../data/text_files\",\n",
    "    glob=\"**/*.txt\", # Pattern to match files basically the files we want to extract\n",
    "    loader_cls=TextLoader, #loader class to use since we are loading txt here we use textloader if it was pdf we would use a pdf loader\n",
    "    loader_kwargs={'encoding': 'utf-8'},\n",
    "    show_progress=True\n",
    ")\n",
    "\n",
    "dir_loader.load()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98fe2642",
   "metadata": {},
   "source": [
    "### Chunking and Embedding and vectorstoredb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6c624e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer #embedding model\n",
    "import chromadb\n",
    "from chromadb.config import Settings\n",
    "import uuid\n",
    "from typing import List,Dict,Any,Tuple \n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dcdc0db1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading embedding model: all-MiniLM-L6-v2\n",
      "Model loaded well. embed dim: 384\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.EmbeddingManager at 0x1dc4635f4d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class EmbeddingManager:\n",
    "    \"\"\"handles document embedding generation using the sentence transformer\"\"\"\n",
    "    def __init__(self, model_name: str = \"all-MiniLM-L6-v2\"): # it uses around 384 dims\n",
    "        \"\"\"\n",
    "        Initialize the embed manager\n",
    "        Args:\n",
    "            model_name: Hugging face model name for sentence embeddings\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.model = None\n",
    "        self._load_model()\n",
    "    def _load_model(self):\n",
    "        \"\"\"Load the sentenceTransformer model\"\"\"\n",
    "        try:\n",
    "            print(f\"Loading embedding model: {self.model_name}\")\n",
    "            self.model = SentenceTransformer(self.model_name)\n",
    "            print(f\"Model loaded well. embed dim: {self.model.get_sentence_embedding_dimension()}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading model {self.model_name}: {e}\")\n",
    "            raise\n",
    "    def generate_embeddings(self, texts: List[str])-> np.ndarray:\n",
    "        \"\"\"\n",
    "        Generate embeddings for a list of texts\n",
    "\n",
    "        Args:\n",
    "            texts: List of text strings to embed\n",
    "\n",
    "        Returns:\n",
    "        numpy array of embeddings with shape (len(text),embedding_dim)\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.model:\n",
    "            raise ValueError(\"Model not loaded\")\n",
    "        \n",
    "        print(f\"Generating embeddings for {len(texts)} texts....\")\n",
    "        embeddings = self.model.encode(texts,show_progress_bar=True)\n",
    "        print(f\"generated embeddings with shape: {embeddings.shape}\")\n",
    "        return embeddings\n",
    "    def get_embedding_dimension(self) -> int:\n",
    "        \"\"\"Get the embedding dim of the model\"\"\"\n",
    "        if not self.model:\n",
    "            raise ValueError('Model not loaded')\n",
    "        return self.model.get_sentence_embedding_dimension()\n",
    "    \n",
    "embedding_manager = EmbeddingManager()\n",
    "embedding_manager"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "741e1915",
   "metadata": {},
   "source": [
    "### VECTOR STORE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39ddd0e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store initialized. Collecction: pdf_documents\n",
      "Existing documents in collection: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<__main__.VectorStore at 0x1dc572c0590>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class VectorStore:\n",
    "    \"\"\"Manages document embeddings in a chromadb vector store\"\"\"\n",
    "\n",
    "    def __init__(self,collection_name: str=\"pdf_documents\", perist_directory: str = \"../data/vector_store\"):\n",
    "        \"\"\"\n",
    "        Initialize the vector store\n",
    "\n",
    "        Args:\n",
    "            collection_name: name of the ChromaDB collection\n",
    "            persist_directory: Directory to persist the vector store (where we will store stuff(the chunk embeddings) locally)\n",
    "        \"\"\"\n",
    "        self.collection_name = collection_name\n",
    "        self.persist_directory = perist_directory\n",
    "        self.client = None\n",
    "        self.collection = None\n",
    "        self._initialize_store()\n",
    "    def _initialize_store(self):\n",
    "        \"\"\"Initialize the ChromaDB client and collection\"\"\"\n",
    "        try:\n",
    "            #Create persistent ChromaDb client\n",
    "            os.makedirs(self.persist_directory, exist_ok=True)\n",
    "            self.client = chromadb.PersistentClient(path=self.persist_directory)\n",
    "\n",
    "            #Get or create collection\n",
    "            self.collection = self.client.get_or_create_collection(\n",
    "                name=self.collection_name,\n",
    "                metadata={\"description\": \"PDF document embeddings for RAG\",\n",
    "                          \"hnsw:space\": \"cosine\"}\n",
    "            )\n",
    "            print(f\"Vector store initialized. Collecction: {self.collection_name}\")\n",
    "            print(f\"Existing documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error inintializing vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "        ## Add document function\n",
    "\n",
    "    def add_documents(self, documents: List[Any], embeddings: np.ndarray):\n",
    "        \"\"\"\n",
    "        Add document and their embeddings to the vector store\n",
    "\n",
    "        Args:\n",
    "            documents: List of Langchain documents\n",
    "            embeddings: Corresponding embeddings for the documents\n",
    "        \"\"\"\n",
    "        if len(documents) != len(embeddings):\n",
    "            raise ValueError(\"Number of documents must match number of embeddings\")\n",
    "        print(f\"Adding {len(documents)} document to vector store..\")\n",
    "\n",
    "        #Prepare data for ChromaDB\n",
    "        ids=[]\n",
    "        metadatas = []\n",
    "        documents_text = []\n",
    "        embeddings_list = []\n",
    "\n",
    "        for i, (doc,embedding) in enumerate(zip(documents, embeddings)):\n",
    "            #Generate unique id\n",
    "            doc_id = f\"doc_{uuid.uuid4().hex[:8]}_{i}\"\n",
    "            ids.append(doc_id)\n",
    "\n",
    "            #prep metadata\n",
    "            metadata = dict(doc.metadata)\n",
    "            metadata['doc_index'] = i\n",
    "            metadata['content_length'] = len(doc.page_content)\n",
    "            metadatas.append(metadata)\n",
    "\n",
    "            #Document content\n",
    "            documents_text.append(doc.page_content)\n",
    "\n",
    "            #Embedding\n",
    "            embeddings_list.append(embedding.tolist())\n",
    "        try:\n",
    "            self.collection.add(\n",
    "                ids=ids,\n",
    "                embeddings=embeddings_list,\n",
    "                metadatas=metadatas,\n",
    "                documents=documents_text,\n",
    "            )\n",
    "            print(f\"Successfully Added {len(documents)} documents to vector store\")\n",
    "            print(f\"Total documents in collection: {self.collection.count()}\")\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error adding docs to vector store: {e}\")\n",
    "            raise\n",
    "\n",
    "vectorstore = VectorStore()\n",
    "vectorstore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4f09e338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3439"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pypdf import PdfReader\n",
    "\n",
    "reader = PdfReader(\"../data/pdf_files/Code_Culture.pdf\")\n",
    "text = \"\"\n",
    "for page in reader.pages:\n",
    "    text+=page.extract_text()+\"\\n\"\n",
    "len(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8b478f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Code Culture - User Guide and FAQ\\nFrequently Asked Questions\\nWhat is Code Culture Code Culture is a community and system designed to help people grow\\nthrough technology disciplined thinking and shared learning It emphasizes building reflecting and\\ncollaborating over passive consumption\\nWho is Code Culture for Code Culture is for people who - Want to learn by building - Are curious\\nabout how systems work - Value discipline reflection and long-term growth - Are willing to contribute\\nnot just consume\\nYou dont need to be an expert just intentional\\nDo I need a technical background No Code Culture supports learners at all levels What matters is\\nyour willingness to think rigorously practice consistently and engage respectfully\\nIs there a fixed learning path No Learning paths emerge from problems projects and collaboration\\nUsers are encouraged to define goals build solutions and reflect on outcomes rather than follow rigid\\ntracks\\nHow do I get started 1 Explore Code Cultures core principles 2 Identify a problem or skill to focus on\\n3 Engage with existing projects or discussions 4 Build something small and iterate\\nIf unsure ask CC for guidance\\nWhat kind of projects belong here Projects that - Solve real problems - Promote learning through\\nexecution - Can be shared documented or reflected upon\\nProjects dont need to be perfect they need to be intentional\\nHow is Code Culture different It prioritizes - Systems thinking over tool obsession - Discipline over\\nhype - Collective growth over individual performance - Understanding over shortcuts\\nWhat is CC CC is Code Cultures AI agent It helps users navigate the platform make decisions using\\nCode Culture principles and find clarity when direction is unclear\\nCan I learn quietly without contributing You can observe initially but long-term growth depends on\\nparticipation Sharing asking thoughtful questions and reflecting openly are encouraged\\nUser Guidelines\\nThese guidelines define how to interact with the site the community and CC\\n1 Be Intentional - Know what you want to learn or build - Ask questions with context - Revisit\\ndecisions with reflection\\nCuriosity is welcome Direction is required\\n2 Build Before You Ask - Attempt a solution first - Identify where youre stuck - Share what you tried\\nEffort-based questions get better guidance\\n3 Think in Systems - Ask why something works - Look for patterns and tradeoffs - Consider\\nlong-term implications\\nAvoid focusing only on tools or shortcuts\\n4 Respect Different Perspectives - Try to understand before critiquing - Explain your reasoning\\nclearly - Assume others are acting in good faith\\nDisagreement is allowed dismissiveness is not\\n5 Share Responsibly - Protect ideas that arent ready - Share lessons others can learn from -\\nDocument failures as clearly as successes\\n6 Optimize for the Collective - Help others when you can - Contribute clarity not noise - Consider\\nreuse and shared value\\n7 Use CC as a Guide Not a Crutch CC helps to clarify thinking surface principles and suggest next\\nsteps but does not replace judgment or effort\\nHow to Ask Good Questions\\nBefore asking - What am I trying to achieve - What have I already tried - Where exactly am I stuck\\nGood questions include - Clear context - Specific constraints - Willingness to iterate\\nFinal Note\\nCode Culture works best when treated as a shared system not a service Bring discipline curiosity\\nand respect and the system will return clarity growth and opportunity\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ca110bd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def clean_pdf_text(text):\n",
    "    # Fix hyphenated line breaks: exam-\\nple → example\n",
    "    text = re.sub(r\"-\\n\", \"\", text)\n",
    "\n",
    "    # Remove weird reference markers: † ‡ § ¶ ` *\n",
    "    text = re.sub(r\"[†‡§¶`∗]\", \"\", text)\n",
    "\n",
    "    # Add space between merged lower→upper case words\n",
    "    text = re.sub(r\"([a-z])([A-Z])\", r\"\\1 \\2\", text)\n",
    "\n",
    "    # Remove duplicate commas\n",
    "    text = re.sub(r\",,+\", \",\", text)\n",
    "\n",
    "    # Normalize multiple newlines\n",
    "    text = re.sub(r\"\\n{2,}\", \"\\n\\n\", text)\n",
    "\n",
    "    return text\n",
    "\n",
    "cleaned_text = clean_pdf_text(text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c3b00c90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#chunking the sample paper\n",
    "\n",
    "def chunk_text(text, chunk_size=500):\n",
    "    chunks = []\n",
    "    start = 0\n",
    "    while start < len(text):\n",
    "        end = start + chunk_size\n",
    "        chunks.append(text[start:end])\n",
    "        start +=chunk_size\n",
    "    return chunks\n",
    "\n",
    "chunks = chunk_text(cleaned_text)\n",
    "\n",
    "len(chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "96600e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating embeddings for 7 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  4.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (7, 384)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# convert text to embeddings\n",
    "text = chunks\n",
    "#Generate the embeddings\n",
    "\n",
    "embeddings = embedding_manager.generate_embeddings(texts=text)\n",
    "\n",
    "#store in the vector db\n",
    "\n",
    "from langchain_core.documents import Document\n",
    "docs = [Document(page_content=c) for c in chunks] #since our chunks are pure text and vectore store on accepts doc type we have to cast it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a62d24c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adding 7 document to vector store..\n",
      "Successfully Added 7 documents to vector store\n",
      "Total documents in collection: 7\n"
     ]
    }
   ],
   "source": [
    "vectorstore.add_documents(docs, embeddings)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15bcba6f",
   "metadata": {},
   "source": [
    "### Rag Retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3fd361d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RAGRetrieval:\n",
    "    \"\"\"Handles query based retrieval from the vector store\"\"\"\n",
    "    def __init__(self, vector_store: VectorStore, embedding_manager: EmbeddingManager):\n",
    "        \"\"\"\n",
    "        Init the retriver\n",
    "        \n",
    "        Args: \n",
    "            vector_store: Vector store containing the document embeddings\n",
    "            embedding_manager: Manger for generating the query eembeddings\n",
    "            \"\"\"\n",
    "        self.vector_store = vector_store\n",
    "        self.embedding_manager = embedding_manager\n",
    "\n",
    "    def retrieve(self,query:str, top_k: int =4, score_threshold: float = 0.0)-> List[Dict[str,Any]]:\n",
    "        \"\"\"\n",
    "        Retrieve relevant documents for a query\n",
    "\n",
    "        Args:\n",
    "            query: the search (users question)\n",
    "            top_k: Number of top results to return\n",
    "            score_threshold: Minimum similarity score threshold\n",
    "\n",
    "        Returns:\n",
    "            List of dictionaries containing retrieved documents and metadata\n",
    "        \"\"\"\n",
    "        print(f\"Retrieving documents for query: '{query}\")\n",
    "        print(f\"Top K: {top_k}, Score Threshold: {score_threshold}\")\n",
    "\n",
    "        #Generate query embedding\n",
    "\n",
    "        query_embedding = self.embedding_manager.generate_embeddings([query])[0]\n",
    "\n",
    "        #Search in vector store\n",
    "        try:\n",
    "            results = self.vector_store.collection.query(\n",
    "                query_embeddings=[query_embedding.tolist()],\n",
    "                n_results=top_k,\n",
    "            )\n",
    "\n",
    "            # process results\n",
    "\n",
    "            retrieved_docs = []\n",
    "\n",
    "            if results['documents'] and results['documents'][0]:\n",
    "                documents = results['documents'][0]\n",
    "                metadatas = results['metadatas'][0]\n",
    "                distances = results['distances'][0]\n",
    "\n",
    "                ids = results['ids'][0]\n",
    "\n",
    "                for i, (doc_id,document,metadata,distance) in enumerate(zip(ids,documents,metadatas,distances)):\n",
    "                    #convert distances to similarity scores (ChromaDB uses cosine distance)\n",
    "                    similarity_score = 1 - distance\n",
    "\n",
    "                    if similarity_score >= score_threshold:\n",
    "                        retrieved_docs.append({\n",
    "                            'id': doc_id,\n",
    "                            'content':document,\n",
    "                            'metadata': metadata,\n",
    "                             'similarity_score': similarity_score,\n",
    "                             'distance': distance,\n",
    "                             'rank': i + 1\n",
    "                        })\n",
    "\n",
    "                print(f\"Retrieved {len(retrieved_docs)} (documents after filtering)\")\n",
    "            else:\n",
    "                print(\"No documents found\")\n",
    "\n",
    "            return retrieved_docs\n",
    "        except Exception as e:\n",
    "            print(f\"Error during retrieval: {e}\")\n",
    "            return[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff48b215",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_ret = RAGRetrieval(vectorstore,embedding_manager)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eb2da080",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is code culture\n",
      "Top K: 4, Score Threshold: 0.0\n",
      "Generating embeddings for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 27.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 4 (documents after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'id': 'doc_6ef2f2db_0',\n",
       "  'content': 'Code Culture - User Guide and FAQ\\nFrequently Asked Questions\\nWhat is Code Culture Code Culture is a community and system designed to help people grow\\nthrough technology disciplined thinking and shared learning It emphasizes building reflecting and\\ncollaborating over passive consumption\\nWho is Code Culture for Code Culture is for people who - Want to learn by building - Are curious\\nabout how systems work - Value discipline reflection and long-term growth - Are willing to contribute\\nnot just consu',\n",
       "  'metadata': {'content_length': 500, 'doc_index': 0},\n",
       "  'similarity_score': 0.7830911874771118,\n",
       "  'distance': 0.21690881252288818,\n",
       "  'rank': 1},\n",
       " {'id': 'doc_093424ad_1',\n",
       "  'content': 'me\\nYou dont need to be an expert just intentional\\nDo I need a technical background No Code Culture supports learners at all levels What matters is\\nyour willingness to think rigorously practice consistently and engage respectfully\\nIs there a fixed learning path No Learning paths emerge from problems projects and collaboration\\nUsers are encouraged to define goals build solutions and reflect on outcomes rather than follow rigid\\ntracks\\nHow do I get started 1 Explore Code Cultures core principles 2 I',\n",
       "  'metadata': {'doc_index': 1, 'content_length': 500},\n",
       "  'similarity_score': 0.5481229424476624,\n",
       "  'distance': 0.45187705755233765,\n",
       "  'rank': 2},\n",
       " {'id': 'doc_184e535f_2',\n",
       "  'content': 'dentify a problem or skill to focus on\\n3 Engage with existing projects or discussions 4 Build something small and iterate\\nIf unsure ask CC for guidance\\nWhat kind of projects belong here Projects that - Solve real problems - Promote learning through\\nexecution - Can be shared documented or reflected upon\\nProjects dont need to be perfect they need to be intentional\\nHow is Code Culture different It prioritizes - Systems thinking over tool obsession - Discipline over\\nhype - Collective growth over ind',\n",
       "  'metadata': {'content_length': 500, 'doc_index': 2},\n",
       "  'similarity_score': 0.4724031686782837,\n",
       "  'distance': 0.5275968313217163,\n",
       "  'rank': 3},\n",
       " {'id': 'doc_266e059a_3',\n",
       "  'content': 'ividual performance - Understanding over shortcuts\\nWhat is CC CC is Code Cultures AI agent It helps users navigate the platform make decisions using\\nCode Culture principles and find clarity when direction is unclear\\nCan I learn quietly without contributing You can observe initially but long-term growth depends on\\nparticipation Sharing asking thoughtful questions and reflecting openly are encouraged\\nUser Guidelines\\nThese guidelines define how to interact with the site the community and CC\\n1 Be In',\n",
       "  'metadata': {'doc_index': 3, 'content_length': 500},\n",
       "  'similarity_score': 0.4586299657821655,\n",
       "  'distance': 0.5413700342178345,\n",
       "  'rank': 4}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_ret.retrieve(query=\"what is code culture\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d2b057d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# queries = [\n",
    "#     \"SIPIT\",\n",
    "#     \"prompt recovery\",\n",
    "#     \"SIPIT algorithm\",\n",
    "#     \"exact prompt recovery\",\n",
    "#     \"recover prompts SIPIT\"\n",
    "# ]\n",
    "\n",
    "# for q in queries:\n",
    "#     results = rag_ret.retrieve(query=q, top_k=3)\n",
    "#     print(f\"\\nQuery: '{q}' → Found {len(results)} docs\")\n",
    "#     if results:\n",
    "#         print(f\"  Best score: {results[0]['similarity_score']:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe75fe24",
   "metadata": {},
   "source": [
    "### Simple rag pipeline with gemini because it's free"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "54187635",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API Key loaded successfully\n",
      "respose: Hello!\n",
      "\n",
      "No, I am not alive in the biological sense. I am an artificial intelligence, a large language model. I don't have a physical body, consciousness, or feelings like living beings do. I exist as code and data on computer servers, designed to process information and communicate with you.\n"
     ]
    }
   ],
   "source": [
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "# 1. Load the variables from .env\n",
    "load_dotenv() \n",
    "\n",
    "my_key = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "# Check if it loaded \n",
    "if my_key:\n",
    "    print(\"API Key loaded successfully\")\n",
    "else:\n",
    "    print(\"API Key not found\")\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(model=\"gemini-2.5-flash\",\n",
    "                             google_api_key=my_key,\n",
    "                             temperature=.1)\n",
    "\n",
    "try: \n",
    "    response = llm.invoke(\"Hello, are you alive?\")\n",
    "    print(f\"respose: {response.content}\")\n",
    "except Exception as e:\n",
    "    print(f\"Connection failed: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b837f2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# simple rag function to retrieve context and generate result\n",
    "\n",
    "def rag_simple(query, retriever, llm, top_k=3):\n",
    "    # retrieve context\n",
    "    results = retriever.retrieve(query,top_k=top_k)\n",
    "    context = \"\\n\\n\".join([doc[\"content\"] for doc in results]) if results else \"\" \n",
    "    if not context:\n",
    "        return \"No relevant context found to answer the question.\"\n",
    "    ## generate the answer using gemini llm\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely.\n",
    "        Context:\n",
    "        {context}\n",
    "\n",
    "        Question:\n",
    "        {query}\n",
    "        \n",
    "        Answer: \n",
    "    \n",
    "    \"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
    "    return response.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2d34340c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'what is INJECTIVE?\n",
      "Top K: 3, Score Threshold: 0.0\n",
      "Generating embeddings for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00,  7.65it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 3 (documents after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The provided context does not define \"INJECTIVE.\"\n"
     ]
    }
   ],
   "source": [
    "answer = rag_simple(\"what is INJECTIVE?\", rag_ret,llm)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e484625a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import google.generativeai as genai\n",
    "\n",
    "# genai.configure(api_key=my_key)\n",
    "\n",
    "# for model in genai.list_models():\n",
    "#     if 'generateContent' in model.supported_generation_methods:\n",
    "#         print(model.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aefbae1",
   "metadata": {},
   "source": [
    "### Enhanced RAG Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "abdcf337",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Retrieving documents for query: 'What is Code culture?\n",
      "Top K: 1, Score Threshold: 0.4\n",
      "Generating embeddings for 1 texts....\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1/1 [00:00<00:00, 48.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "generated embeddings with shape: (1, 384)\n",
      "Retrieved 1 (documents after filtering)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: Code Culture is a community and system designed to help people grow through technology, disciplined thinking, and shared learning, emphasizing building, reflecting, and collaborating over passive consumption.\n",
      "Sources: [{'source': 'unknown', 'page': 'unknown', 'score': 0.7837700247764587, 'preview': 'Code Culture - User Guide and FAQ\\nFrequently Asked Questions\\nWhat is Code Culture Code Culture is a community and system designed to help people grow\\nthrough technology disciplined thinking and shared learning It emphasizes building reflecting and\\ncollaborating over passive consumption\\nWho is Code C...'}]\n",
      "Confidence: 0.7837700247764587\n",
      "Context Preview: Machine Learning Basics\n",
      "\n",
      "Machine learning is a subset of artificial intelligence that enables systems to learn and improve\n",
      "from experience without being explicitly programmed. It focuses on developing computer programs\n",
      "that can access data and use it to learn for themselves.\n",
      "\n",
      "Types of Machine Learning:\n",
      "1. Supervised Learning: Learning with labeled data\n",
      "2. Unsupervised Learning: Finding patterns in unlabeled data\n",
      "3. Reinforcement Learning: Learning through rewards and penalties\n",
      "\n",
      "Applications include image recognition, speech processing, and recommendation systems\n",
      "\n",
      "\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "def rag_advanced(query, retriever, llm, top_k=1, min_score=0.2, return_context=False):\n",
    "    \"\"\"\n",
    "    RAG Pipeline with extra features:\n",
    "    - Returns answer, sources, confidence score, and optionally full context.\n",
    "    \"\"\"\n",
    "\n",
    "    results = retriever.retrieve(query,top_k,min_score)\n",
    "    if not results:\n",
    "        return {'answer': 'No relevant context found.', 'sources':[],'confidence':0.0, 'context':''}\n",
    "    context = \"\\n\\n\".join([doc[\"content\"] for doc in results]) if results else \"\" \n",
    "    sources = [{\n",
    "        'source': doc['metadata'].get('source_file', doc['metadata'].get('source', 'unknown')),\n",
    "        'page': doc['metadata'].get('page','unknown'),\n",
    "        'score': doc['similarity_score'],\n",
    "        'preview': doc['content'][:300]+'...',\n",
    "    }for doc in results]\n",
    "    confidence = max([doc['similarity_score'] for doc in results])\n",
    "\n",
    "    #Generate answer\n",
    "\n",
    "    prompt = f\"\"\"Use the following context to answer the question concisely. \\nContext:\\n{context}\\n\\nQuestion: {query}\\n\\nAnswer:\"\"\"\n",
    "    response = llm.invoke([prompt.format(context=context,query=query)])\n",
    "\n",
    "    output = {\n",
    "        'answer': response.content,\n",
    "        'sources': sources,\n",
    "        'confidence': confidence,\n",
    "    }\n",
    "    if return_context:\n",
    "        output['context'] = content\n",
    "    return output\n",
    "result = rag_advanced(\"What is Code culture?\", rag_ret,llm,1,.4,return_context=True)\n",
    "\n",
    "print(f\"Answer: {result['answer']}\")\n",
    "print(f\"Sources: {result['sources']}\")\n",
    "print(f\"Confidence: {result['confidence']}\")\n",
    "print(f\"Context Preview: {result['context']}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "code_culture (3.13.7)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
